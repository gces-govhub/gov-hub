# üöÄ Implementa√ß√£o de Agente de IA para Extra√ß√£o Autom√°tica de Identificadores

## üéØ Objetivo

Expandir o pipeline de dados do GovHubbr com a integra√ß√£o de um Agente de IA respons√°vel pela extra√ß√£o autom√°tica de identificadores em campos de observa√ß√£o textual nas bases de dados p√∫blicas.

Exemplos de identificadores extra√≠dos:
- num_transf
- contrato_num
- contrato_licitacao
- instrumento_numero
- nc_aux
- nc_prefix
- nc_posfix
- nc


Esta funcionalidade √© cr√≠tica para aprimorar a integra√ß√£o de bases de dados, automatizar o cruzamento de informa√ß√µes e fortalecer a qualidade das an√°lises realizadas.

---

## üì¶ Depend√™ncias T√©cnicas

- **Python 3.10+:** Ambiente de desenvolvimento principal.
- **HuggingFace Transformers:**
    - Modelo: BERTimbau Base para NER.
    - Task: Token-Classification para extrair entidades como NF, Contrato, Processo.
- **pandas**: Manipula√ß√£o de datasets tabulares.
- **Apache Airflow**: Orquestra√ß√£o do pipeline de execu√ß√£o.
- **DBT**: Transforma√ß√µes intermedi√°rias no pipeline de dados.
- **PostgreSQL**: Armazenamento dos dados extra√≠dos.

### Depend√™ncias Adicionais para PoC
- OpenAI API ou Alternativa Open Source (por exemplo, HuggingFace Inference API).
- Jupyter Notebook: Ambiente de prototipa√ß√£o r√°pida para extra√ß√£o de informa√ß√µes.
- Transformers (HuggingFace): Para testes com modelos p√∫blicos de extra√ß√£o textual.
- openai Python SDK (se usar OpenAI).

---

## üß™ Fase de Teste de Conceito e Avalia√ß√£o de Estrat√©gias de Extra√ß√£o
Antes da implementa√ß√£o definitiva do Agente de IA no pipeline de produ√ß√£o, ser√° realizada uma Fase de Teste de Conceito (PoC) para:
- Avaliar a viabilidade da extra√ß√£o autom√°tica de identificadores em campos de texto livres.
- Testar rapidamente diferentes estrat√©gias de NLP utilizando APIs j√° dispon√≠veis.
- Identificar desafios e limita√ß√µes pr√°ticas na interpreta√ß√£o dos textos de observa√ß√£o.

### Estrat√©gia do Teste:
1. Ambiente:
    - Rodar os experimentos iniciais em Jupyter Notebooks.
    - Utilizar amostras reais dos campos observacao da Tabela B.

2. Ferramentas:
    - GPT-3.5-turbo via OpenAI API para tarefas de extra√ß√£o textual supervisionada.
    - Alternativas Open Source via HuggingFace, caso necess√°rio.

3. Metodologia:
    - Inserir exemplos reais de campos de observa√ß√£o.
    - Formular prompts para extrair explicitamente os identificadores desejados.

4. Avaliar:
    - Se o modelo consegue extrair corretamente os campos (num_transf, contrato_num, etc).
    - Se h√° confus√£o ou ambiguidade.
    - Tempo de infer√™ncia, custo e viabilidade pr√°tica.

5. Crit√©rios de Sucesso:
    - Precis√£o acima de 85% na extra√ß√£o dos identificadores relevantes em pelo menos 80% dos casos testados.
    - Custo computacional e de API dentro dos limites vi√°veis para posterior migra√ß√£o para BERTimbau.


## üõ†Ô∏è Arquitetura de Integra√ß√£o da Funcionalidade

1. **Input (Bronze):**
    - Tabela A: (num_transf, contrato_num, etc).
    - Tabela B: (observacao).
2. Execu√ß√£o da Extra√ß√£o:
    - Durante a transforma√ß√£o no DBT, um script externo Python (chamado via macro ou dbt-python-model) √© invocado.
    - O agente de IA processa o campo observacao da Tabela B e extrai os identificadores.
3. Matching e Merge:
    - Ap√≥s a extra√ß√£o, realiza-se o JOIN entre:
        - Identificadores extra√≠dos da Tabela B
        - Identificadores originais da Tabela A
    - Match feito usando l√≥gica de toler√¢ncia a erro m√≠nima (fuzzy matching controlado se necess√°rio).
4. Output (Silver):
    - Nova Tabela Silver consolidando:
        - Dados estruturados da Tabela A
        - Informa√ß√µes adicionais da Tabela B

Esse processamento ocorrer√° **dentro do fluxo ETL** j√° existente, entre a transforma√ß√£o DBT e o carregamento final no PostgreSQL.

---

