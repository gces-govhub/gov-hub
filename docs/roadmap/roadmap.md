# üöÄ Implementa√ß√£o de Agente de IA para Extra√ß√£o Autom√°tica de Identificadores

## üéØ Objetivo

Expandir o pipeline de dados do GovHubbr com a integra√ß√£o de um Agente de IA respons√°vel pela extra√ß√£o autom√°tica de identificadores em campos de observa√ß√£o textual nas bases de dados p√∫blicas.

Exemplos de identificadores extra√≠dos:

- num_transf
- contrato_num
- contrato_licitacao
- instrumento_numero
- nc_aux
- nc_prefix
- nc_posfix
- nc


Esta funcionalidade √© cr√≠tica para aprimorar a integra√ß√£o de bases de dados, automatizar o cruzamento de informa√ß√µes e fortalecer a qualidade das an√°lises realizadas.

---

## üì¶ Depend√™ncias T√©cnicas

- **Python 3.10+:** Ambiente de desenvolvimento principal.
- **HuggingFace Transformers:**
    - Modelo: BERTimbau Base para NER.
    - Task: Token-Classification para extrair entidades como NF, Contrato, Processo.
- **pandas**: Manipula√ß√£o de datasets tabulares.
- **Apache Airflow**: Orquestra√ß√£o do pipeline de execu√ß√£o.
- **DBT**: Transforma√ß√µes intermedi√°rias no pipeline de dados.
- **PostgreSQL**: Armazenamento dos dados extra√≠dos.

### Depend√™ncias Adicionais para PoC
- OpenAI API ou Alternativa Open Source (por exemplo, HuggingFace Inference API).
- Jupyter Notebook: Ambiente de prototipa√ß√£o r√°pida para extra√ß√£o de informa√ß√µes.
- Transformers (HuggingFace): Para testes com modelos p√∫blicos de extra√ß√£o textual.

---

## üß™ Fase de Teste de Conceito e Avalia√ß√£o de Estrat√©gias de Extra√ß√£o
Antes da implementa√ß√£o definitiva do Agente de IA no pipeline de produ√ß√£o, ser√° realizada uma Fase de Teste de Conceito (PoC) para:

- Avaliar a viabilidade da extra√ß√£o autom√°tica de identificadores em campos de texto livres.
- Testar rapidamente diferentes estrat√©gias de NLP utilizando APIs j√° dispon√≠veis.
- Identificar desafios e limita√ß√µes pr√°ticas na interpreta√ß√£o dos textos de observa√ß√£o.

### Estrat√©gia do Teste:
1. Ambiente:
    - Rodar os experimentos iniciais em Jupyter Notebooks.
    - Utilizar amostras reais dos campos observacao da Tabela B.

2. Ferramentas:
    - OpenAI API para tarefas de extra√ß√£o textual supervisionada.
    - Alternativas Open Source, caso necess√°rio.

3. Metodologia:
    - Inserir exemplos reais de campos de observa√ß√£o.
    - Formular prompts para extrair explicitamente os identificadores desejados.

4. Avaliar:
    - Se o modelo consegue extrair corretamente os campos (num_transf, contrato_num, etc).
    - Se h√° confus√£o ou ambiguidade.
    - Tempo de infer√™ncia, custo e viabilidade pr√°tica.

5. Crit√©rios de Sucesso:
    - Precis√£o acima de 85% na extra√ß√£o dos identificadores relevantes em pelo menos 80% dos casos testados.
    - Custo computacional e de API dentro dos limites vi√°veis para posterior migra√ß√£o para BERTimbau.


## üõ†Ô∏è Arquitetura de Integra√ß√£o da Funcionalidade

1. **Input (Bronze):**
    - Tabela A: (num_transf, contrato_num, etc).
    - Tabela B: (observacao).
2. Execu√ß√£o da Extra√ß√£o:
    - Durante a transforma√ß√£o no DBT, um script externo Python (chamado via macro ou dbt-python-model) √© invocado.
    - O agente de IA processa o campo observacao da Tabela B e extrai os identificadores.
3. Matching e Merge:
    - Ap√≥s a extra√ß√£o, realiza-se o JOIN entre:
        - Identificadores extra√≠dos da Tabela B
        - Identificadores originais da Tabela A
    - Match feito usando l√≥gica de toler√¢ncia a erro m√≠nima.
4. Output (Silver):
    - Nova Tabela Silver consolidando:
        - Dados estruturados da Tabela A
        - Informa√ß√µes adicionais da Tabela B

Esse processamento ocorrer√° **dentro do fluxo ETL** j√° existente, entre a transforma√ß√£o DBT e o carregamento final no PostgreSQL.

---

# üìÜ Planejamento por Vers√µes

## üìç Vers√£o 1.0.0 ‚Äî Estrutura√ß√£o Inicial e Ambienta√ß√£o

**Objetivos:**

- Aprimorar a documenta√ß√£o do projeto e seus componentes.
- Realizar estudo preliminar sobre a viabilidade de extra√ß√£o autom√°tica de identificadores.
- Revisar e organizar o ambiente de desenvolvimento para futuras implementa√ß√µes.
- Definir os primeiros requisitos t√©cnicos para o Teste de Conceito (PoC).


**Entregas:**

- Atualiza√ß√£o e melhoria das documenta√ß√µes MkDocs existentes.
- Planejamento do escopo do Teste de Conceito (PoC).

---

## üìç Vers√£o 1.1.0 ‚Äî Teste de Conceito de Extra√ß√£o de Identificadores

**Objetivos:**

- Desenvolver prot√≥tipos de extra√ß√£o utilizando modelos de linguagem via HuggingFace Transformers.
- Implementar teste de conceito alternativo utilizando OpenAI API (ou outro modelo gratuito) em ambiente Jupyter Notebook.
- Avaliar o desempenho das abordagens quanto √† extra√ß√£o correta dos identificadores.
- Definir a solu√ß√£o t√©cnica a ser implementada no pipeline definitivo.

**Entregas:**

- Branch `feature/ai-extraction-poc` criado e publicado.
- Scripts de extra√ß√£o com BERTimbau documentados e versionados.
- Relat√≥rio t√©cnico de avalia√ß√£o comparativa de abordagens.

---

## üìç Vers√£o 2.0.0 ‚Äî Implementa√ß√£o do Agente Definitivo e Integra√ß√£o no Pipeline

**Objetivos:**

- Implementar o agente de IA definitivo baseado na solu√ß√£o aprovada (HuggingFace + BERTimbau).
- Integrar o agente de extra√ß√£o ao pipeline de dados DBT.
- Realizar o processo de matching e merge entre as Tabelas A e B, consolidando a nova Tabela Silver
- Automatizar a execu√ß√£o do processo dentro do Airflow.
- Produzir documenta√ß√£o detalhada para opera√ß√£o e manuten√ß√£o da funcionalidade.

**Entregas:**

- Branch `feature/ai-extraction-final` criada e mergeada.
- Pipeline DBT atualizado com execu√ß√£o da extra√ß√£o e integra√ß√£o dos dados.
- Nova Tabela Silver consolidada dispon√≠vel em PostgreSQL.
- Documenta√ß√£o da funcionalidade publicada.


# üé° √âpicos, Features e Hist√≥rias de Usu√°rio

## üìö √âpico 1: Organiza√ß√£o e Prepara√ß√£o Inicial
> Prepara√ß√£o do ambiente, documenta√ß√£o e an√°lise preliminar.

- **Feature 1.1: Atualizar a documenta√ß√£o t√©cnica do projeto**
    - (Sem hist√≥ria de usu√°rio direta)

- **Feature 1.2: Estudo dos padr√µes de observa√ß√£o**
    - **Hist√≥ria de Usu√°rio 1**:  
      _Como cientista de dados, quero entender os padr√µes dos campos de observa√ß√£o para planejar a melhor abordagem de extra√ß√£o._

- **Feature 1.3: Defini√ß√£o do planejamento do PoC**
    - **Hist√≥ria de Usu√°rio 2**:  
      _Como analista de dados, quero definir previamente as estrat√©gias de extra√ß√£o para guiar o desenvolvimento do Teste de Conceito._

---

## üìö √âpico 2: Teste de Conceito para Extra√ß√£o de Identificadores
> Prototipagem, teste e avalia√ß√£o de abordagens de IA para extra√ß√£o.

- **Feature 2.1: Desenvolvimento de prot√≥tipo usando OpenAI API**
    - **Hist√≥ria de Usu√°rio 3**:  
      _Como cientista de dados, quero testar a extra√ß√£o de identificadores usando modelos de linguagem prontos para validar viabilidade r√°pida._

- **Feature 2.2: Desenvolvimento de prot√≥tipo usando HuggingFace Transformers**
    - **Hist√≥ria de Usu√°rio 4**:  
      _Como cientista de dados, quero desenvolver um prot√≥tipo open-source para garantir independ√™ncia tecnol√≥gica e redu√ß√£o de custos._

- **Feature 2.3: Avalia√ß√£o e compara√ß√£o das abordagens**
    - **Hist√≥ria de Usu√°rio 5**:  
      _Como analista de dados, quero comparar o desempenho dos modelos para escolher a melhor abordagem para produ√ß√£o._

- **Feature 2.4: Documento de decis√£o t√©cnica**
    - (Sem hist√≥ria de usu√°rio direta.)

---

## üìö √âpico 3: Desenvolvimento e Integra√ß√£o do Agente Definitivo
> Constru√ß√£o e implanta√ß√£o do agente final no pipeline de produ√ß√£o.

- **Feature 3.1: Implementar agente HuggingFace Transformers definitivo**
    - **Hist√≥ria de Usu√°rio 6**:  
      _Como analista de dados, quero contar com um agente de extra√ß√£o treinado e validado para automatizar o processamento dos dados._

- **Feature 3.2: Integra√ß√£o no pipeline DBT**
    - **Hist√≥ria de Usu√°rio 7**:  
      _Como engenheiro de dados, quero integrar a extra√ß√£o no DBT para padronizar a transforma√ß√£o dos dados sem processos manuais._

- **Feature 3.3: Implementar l√≥gica de matching e merge entre tabelas**
    - **Hist√≥ria de Usu√°rio 8**:  
      _Como analista de dados, quero garantir o cruzamento correto de dados entre tabelas para consolidar informa√ß√µes de forma automatizada._

- **Feature 3.4: Automatizar execu√ß√£o no Airflow**
    - **Hist√≥ria de Usu√°rio 9**:  
      _Como engenheiro DevOps, quero automatizar a orquestra√ß√£o da extra√ß√£o para manter o pipeline escal√°vel e confi√°vel._

- **Feature 3.5: Atualizar a Tabela Silver consolidada**
    - **Hist√≥ria de Usu√°rio 10**:  
      _Como gestor p√∫blico, quero acessar dashboards e relat√≥rios baseados em dados consolidados para facilitar auditorias e decis√µes._

---
